# HandWave Phase 1 Implementation Plan (React + TypeScript + Vite)

## Overview

Build a Chrome extension that detects and tracks hands in real-time using TensorFlow.js HandPose, displays a draggable camera overlay with debug visualization, and provides toggle controls via extension popup. Built with React 18+, TypeScript, and Vite for modern DX and maintainability.

## Architecture

### Tech Stack

- **React 18+** with TypeScript for UI components
- **Vite** for blazing-fast builds, HMR, and optimized bundling
- **TensorFlow.js** with HandPose model (modular for future swapping)
- **Tailwind CSS** for utility-first styling
- **Chrome Extension Manifest V3**
- **@types/chrome** for TypeScript extension API types

### File Structure

```
handwave-extension/
â”œâ”€â”€ manifest.json (generated by Vite plugin)
â”œâ”€â”€ vite.config.ts (multi-entry build config)
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ package.json
â”œâ”€â”€ tailwind.config.js
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ background/
â”‚   â”‚   â””â”€â”€ index.ts (service worker)
â”‚   â”œâ”€â”€ content/
â”‚   â”‚   â””â”€â”€ index.tsx (React content script entry)
â”‚   â”œâ”€â”€ overlay/
â”‚   â”‚   â”œâ”€â”€ OverlayApp.tsx (root overlay component)
â”‚   â”‚   â”œâ”€â”€ CameraView.tsx (video + canvas rendering)
â”‚   â”‚   â”œâ”€â”€ DebugPanel.tsx (FPS, hand data display)
â”‚   â”‚   â”œâ”€â”€ useDraggable.ts (drag/resize hook)
â”‚   â”‚   â””â”€â”€ overlay.css
â”‚   â”œâ”€â”€ popup/
â”‚   â”‚   â”œâ”€â”€ PopupApp.tsx (root popup component)
â”‚   â”‚   â”œâ”€â”€ ToggleSwitch.tsx (enable/disable)
â”‚   â”‚   â”œâ”€â”€ CameraSelector.tsx (device picker)
â”‚   â”‚   â””â”€â”€ popup.css
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ handDetection.ts (TensorFlow.js wrapper)
â”‚   â”‚   â”œâ”€â”€ fingerState.ts (finger extension logic)
â”‚   â”‚   â””â”€â”€ debugRenderer.ts (canvas drawing helpers)
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”œâ”€â”€ hand.types.ts (Hand, Landmark interfaces)
â”‚   â”‚   â””â”€â”€ message.types.ts (extension message types)
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useHandDetection.ts (detection loop hook)
â”‚   â”‚   â”œâ”€â”€ useCamera.ts (camera permission/stream)
â”‚   â”‚   â””â”€â”€ useExtensionState.ts (chrome.storage wrapper)
â”‚   â””â”€â”€ shared/
â”‚       â””â”€â”€ constants.ts (FPS targets, config)
â””â”€â”€ public/
    â””â”€â”€ icons/ (16, 48, 128px)
```

## Implementation Steps

### 1. Project Setup with Vite

Initialize project using Vite React-TS template:

```bash
npm create vite@latest handwave-extension -- --template react-ts
cd handwave-extension
npm install
```

Install dependencies:

```bash
# Core dependencies
npm install @tensorflow/tfjs @tensorflow-models/handpose
npm install @types/chrome -D

# Vite plugin for Chrome extensions
npm install @crxjs/vite-plugin -D

# Tailwind CSS
npm install -D tailwindcss postcss autoprefixer
npx tailwindcss init -p
```

Configure `vite.config.ts` for multi-entry extension build:

- Background worker entry
- Content script entry (React)
- Popup entry (React)
- Overlay entry (React iframe)

Configure `manifest.json` template for Vite to process:

- Manifest V3 schema
- Permissions: `activeTab`, `storage`, `<all_urls>` for camera
- Background service worker
- Content scripts injection
- Action (popup)

### 2. TypeScript Type Definitions

Create `src/types/hand.types.ts`:

```typescript
export interface Landmark {
  x: number; // normalized [0, 1]
  y: number;
  z: number;
}

export interface Hand {
  landmarks: Landmark[];
  confidence: number;
  fingersExtended: boolean[]; // [thumb, index, middle, ring, pinky]
}

export interface HandDetectionResult {
  hands: Hand[];
  fps: number;
  timestamp: number;
}
```

Create `src/types/message.types.ts` for extension messaging:

```typescript
export enum MessageType {
  ENABLE_EXTENSION = 'ENABLE_EXTENSION',
  DISABLE_EXTENSION = 'DISABLE_EXTENSION',
  UPDATE_SETTINGS = 'UPDATE_SETTINGS',
  HAND_DATA = 'HAND_DATA'
}

export interface ExtensionMessage {
  type: MessageType;
  payload?: any;
}
```

### 3. TensorFlow.js HandPose Module

Create `src/utils/handDetection.ts` as modular, swappable wrapper:

```typescript
import * as tf from '@tensorflow/tfjs';
import * as handpose from '@tensorflow-models/handpose';

let model: handpose.HandPose | null = null;

export async function initModel(): Promise<void> {
  await tf.setBackend('webgl');
  model = await handpose.load();
}

export async function detectHands(video: HTMLVideoElement): Promise<Hand[]> {
  if (!model) throw new Error('Model not initialized');
  
  const predictions = await model.estimateHands(video);
  
  return predictions.map(pred => ({
    landmarks: pred.landmarks.map(l => ({
      x: l[0] / video.videoWidth,
      y: l[1] / video.videoHeight,
      z: l[2]
    })),
    confidence: pred.handInViewConfidence
  }));
}
```

### 4. Custom React Hooks

#### `src/hooks/useCamera.ts`

```typescript
export function useCamera() {
  const [stream, setStream] = useState<MediaStream | null>(null);
  const [devices, setDevices] = useState<MediaDeviceInfo[]>([]);
  const [error, setError] = useState<string | null>(null);
  
  const requestCamera = async (deviceId?: string) => {
    // getUserMedia logic
  };
  
  const enumerateDevices = async () => {
    // List camera devices
  };
  
  return { stream, devices, error, requestCamera, enumerateDevices };
}
```

#### `src/hooks/useHandDetection.ts`

```typescript
export function useHandDetection(videoRef: RefObject<HTMLVideoElement>) {
  const [hands, setHands] = useState<Hand[]>([]);
  const [fps, setFps] = useState(0);
  const [isRunning, setIsRunning] = useState(false);
  
  useEffect(() => {
    if (!isRunning || !videoRef.current) return;
    
    let animationId: number;
    let lastTime = performance.now();
    let frameCount = 0;
    
    const detectionLoop = async () => {
      const detectedHands = await detectHands(videoRef.current!);
      
      // Process finger states
      const processedHands = detectedHands.map(hand => ({
        ...hand,
        fingersExtended: detectFingerStates(hand.landmarks)
      }));
      
      setHands(processedHands);
      
      // Calculate FPS
      frameCount++;
      const now = performance.now();
      if (now - lastTime >= 1000) {
        setFps(frameCount);
        frameCount = 0;
        lastTime = now;
      }
      
      animationId = requestAnimationFrame(detectionLoop);
    };
    
    detectionLoop();
    
    return () => cancelAnimationFrame(animationId);
  }, [isRunning]);
  
  return { hands, fps, isRunning, setIsRunning };
}
```

#### `src/hooks/useExtensionState.ts`

```typescript
export function useExtensionState() {
  const [enabled, setEnabled] = useState(false);
  const [debugMode, setDebugMode] = useState(true); // default on for Phase 1
  
  useEffect(() => {
    // Load from chrome.storage.sync
    chrome.storage.sync.get(['enabled', 'debugMode'], (result) => {
      setEnabled(result.enabled ?? false);
      setDebugMode(result.debugMode ?? true);
    });
  }, []);
  
  const updateState = (key: string, value: any) => {
    chrome.storage.sync.set({ [key]: value });
  };
  
  return { enabled, debugMode, updateState };
}
```

#### `src/hooks/useDraggable.ts`

```typescript
export function useDraggable(ref: RefObject<HTMLDivElement>) {
  const [position, setPosition] = useState({ x: 20, y: 20 });
  const [isDragging, setIsDragging] = useState(false);
  
  // Mouse event handlers for dragging
  // Support for resize handles
  
  return { position, isDragging, ...handlers };
}
```

### 5. Overlay React Components

#### `src/overlay/OverlayApp.tsx` (Root)

```typescript
export function OverlayApp() {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const overlayRef = useRef<HTMLDivElement>(null);
  
  const { stream, error, requestCamera } = useCamera();
  const { hands, fps, isRunning, setIsRunning } = useHandDetection(videoRef);
  const { position, isDragging } = useDraggable(overlayRef);
  const { debugMode } = useExtensionState();
  
  useEffect(() => {
    initModel().then(() => {
      requestCamera();
      setIsRunning(true);
    });
  }, []);
  
  return (
    <div 
      ref={overlayRef}
      className="fixed z-[9999] rounded-lg shadow-2xl border-2 border-blue-500"
      style={{ left: position.x, top: position.y }}
    >
      <CameraView 
        videoRef={videoRef}
        canvasRef={canvasRef}
        stream={stream}
        hands={hands}
        debugMode={debugMode}
      />
      {debugMode && <DebugPanel hands={hands} fps={fps} />}
    </div>
  );
}
```

#### `src/overlay/CameraView.tsx`

```typescript
interface Props {
  videoRef: RefObject<HTMLVideoElement>;
  canvasRef: RefObject<HTMLCanvasElement>;
  stream: MediaStream | null;
  hands: Hand[];
  debugMode: boolean;
}

export function CameraView({ videoRef, canvasRef, stream, hands, debugMode }: Props) {
  useEffect(() => {
    if (videoRef.current && stream) {
      videoRef.current.srcObject = stream;
    }
  }, [stream]);
  
  // Draw skeleton on canvas
  useEffect(() => {
    if (!canvasRef.current || !debugMode) return;
    
    const ctx = canvasRef.current.getContext('2d')!;
    ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
    
    hands.forEach((hand, idx) => {
      drawHandSkeleton(ctx, hand, idx === 0 ? 'blue' : 'red');
      drawLandmarkIndices(ctx, hand.landmarks);
    });
  }, [hands, debugMode]);
  
  return (
    <div className="relative w-[640px] h-[480px]">
      <video
        ref={videoRef}
        autoPlay
        playsInline
        className="absolute inset-0 w-full h-full"
      />
      <canvas
        ref={canvasRef}
        width={640}
        height={480}
        className="absolute inset-0 pointer-events-none"
      />
    </div>
  );
}
```

#### `src/overlay/DebugPanel.tsx`

```typescript
interface Props {
  hands: Hand[];
  fps: number;
}

export function DebugPanel({ hands, fps }: Props) {
  return (
    <div className="bg-black/80 text-white p-3 text-xs font-mono">
      <div>FPS: {fps}</div>
      <div>Hands: {hands.length}</div>
      {hands.map((hand, idx) => (
        <div key={idx} className="mt-2">
          <div>Hand {idx + 1}: {(hand.confidence * 100).toFixed(1)}%</div>
          <div className="flex gap-2 mt-1">
            {['ğŸ‘', 'â˜ï¸', 'ğŸ–•', 'ğŸ’', 'ğŸ¤™'].map((emoji, i) => (
              <span key={i} className={hand.fingersExtended[i] ? 'opacity-100' : 'opacity-30'}>
                {emoji}
              </span>
            ))}
          </div>
        </div>
      ))}
    </div>
  );
}
```

### 6. Onboarding Flow

Multi-step onboarding component that appears:
- **On first install** (when `onboardingCompleted` is not set in chrome.storage)
- **When user clicks extension icon** and hasn't completed setup
- **When user clicks info/help button** in popup (to view again)

#### `src/popup/OnboardingFlow.tsx`

```typescript
interface Props {
  onComplete: () => void;
}

export function OnboardingFlow({ onComplete }: Props) {
  const [step, setStep] = useState(0);
  const [cameraError, setCameraError] = useState<string | null>(null);
  const { requestCamera } = useCamera();
  
  const steps = [
    {
      title: "Welcome to Minority Report ğŸ‘‹",
      content: "Here's how it works: [Placeholder for future detailed instructions about gesture control and features]",
      buttonText: "Get Started"
    },
    {
      title: "Camera Access Required",
      content: "To detect your hand gestures, Minority Report needs access to your camera. Please click 'Grant Camera Access' and allow camera permissions when prompted by your browser. All processing happens locally on your deviceâ€”your video never leaves your computer.",
      buttonText: "Grant Camera Access",
      action: async () => {
        try {
          setCameraError(null);
          await requestCamera();
          setStep(step + 1);
        } catch (error) {
          setCameraError("Camera access denied. Please check your browser permissions and try again.");
        }
      }
    },
    {
      title: "You're All Set!",
      content: "[Placeholder for future instructions about using gestures, enabling the extension, and tips for best results]",
      buttonText: "Start Using Minority Report"
    }
  ];
  
  const currentStep = steps[step];
  
  const handleNext = () => {
    if (currentStep.action) {
      currentStep.action();
    } else if (step < steps.length - 1) {
      setStep(step + 1);
    } else {
      onComplete();
    }
  };
  
  return (
    <div className="w-[400px] p-6 bg-white">
      <div className="mb-4">
        <div className="flex gap-2 mb-4">
          {steps.map((_, idx) => (
            <div
              key={idx}
              className={`h-2 flex-1 rounded ${
                idx <= step ? 'bg-blue-500' : 'bg-gray-200'
              }`}
            />
          ))}
        </div>
        <h2 className="text-2xl font-bold mb-2">{currentStep.title}</h2>
        <p className="text-gray-600 mb-6 whitespace-pre-line">{currentStep.content}</p>
        
        {cameraError && (
          <div className="mb-4 p-3 bg-red-50 border border-red-200 rounded text-red-700 text-sm">
            {cameraError}
          </div>
        )}
      </div>
      
      <button
        onClick={handleNext}
        className="w-full bg-blue-500 text-white py-2 px-4 rounded hover:bg-blue-600 transition-colors"
      >
        {currentStep.buttonText}
      </button>
      
      {step > 0 && (
        <button
          onClick={() => {
            setStep(step - 1);
            setCameraError(null);
          }}
          className="mt-2 w-full text-gray-500 hover:text-gray-700 text-sm"
        >
          Back
        </button>
      )}
    </div>
  );
}
```

#### `src/hooks/useOnboarding.ts`

```typescript
export function useOnboarding() {
  const [showOnboarding, setShowOnboarding] = useState(false);
  const [hasCompletedOnboarding, setHasCompletedOnboarding] = useState(false);
  
  useEffect(() => {
    // Check if user has completed onboarding
    chrome.storage.sync.get(['onboardingCompleted'], (result) => {
      const completed = result.onboardingCompleted ?? false;
      setHasCompletedOnboarding(completed);
      // Show onboarding if not completed (first time setup)
      setShowOnboarding(!completed);
    });
  }, []);
  
  const completeOnboarding = () => {
    chrome.storage.sync.set({ onboardingCompleted: true });
    setHasCompletedOnboarding(true);
    setShowOnboarding(false);
  };
  
  const showOnboardingAgain = () => {
    setShowOnboarding(true);
  };
  
  return {
    showOnboarding,
    hasCompletedOnboarding,
    completeOnboarding,
    showOnboardingAgain
  };
}
```

### 7. Popup React Components

#### `src/popup/PopupApp.tsx`

```typescript
export function PopupApp() {
  const { enabled, debugMode, updateState } = useExtensionState();
  const { devices, enumerateDevices } = useCamera();
  const { showOnboarding, completeOnboarding, showOnboardingAgain } = useOnboarding();
  
  useEffect(() => {
    enumerateDevices();
  }, []);
  
  const toggleExtension = () => {
    const newState = !enabled;
    updateState('enabled', newState);
    
    chrome.runtime.sendMessage({
      type: newState ? MessageType.ENABLE_EXTENSION : MessageType.DISABLE_EXTENSION
    });
  };
  
  // Show onboarding if not completed
  if (showOnboarding) {
    return <OnboardingFlow onComplete={completeOnboarding} />;
  }
  
  return (
    <div className="w-[320px] p-4 bg-gray-50">
      <div className="flex justify-between items-center mb-4">
        <h1 className="text-xl font-bold">ğŸ‘‹ HandWave</h1>
        <button
          onClick={showOnboardingAgain}
          className="text-xs text-gray-500 hover:text-gray-700"
          title="Show onboarding again"
        >
          â„¹ï¸
        </button>
      </div>
      
      <ToggleSwitch 
        checked={enabled}
        onChange={toggleExtension}
        label="Enable Extension"
      />
      
      <CameraSelector 
        devices={devices}
        onChange={(deviceId) => updateState('cameraId', deviceId)}
      />
      
      <label className="flex items-center mt-4">
        <input
          type="checkbox"
          checked={debugMode}
          onChange={(e) => updateState('debugMode', e.target.checked)}
        />
        <span className="ml-2">Debug Mode</span>
      </label>
      
      <div className={`mt-4 p-2 rounded ${enabled ? 'bg-green-100' : 'bg-red-100'}`}>
        Status: {enabled ? 'âœ“ Active' : 'â—‹ Inactive'}
      </div>
    </div>
  );
}
```

### 6.5. Onboarding Flow

#### `src/popup/OnboardingFlow.tsx`

Multi-step onboarding component that appears:

- On first install (when `onboardingCompleted` is not set in chrome.storage)
- When user clicks info/help button in popup

Steps:

1. **Welcome Screen**: "Welcome to HandWave ğŸ‘‹" - Brief intro about gesture control
2. **Camera Permission**: Instructions to grant camera access, explains local processing
3. **How It Works**: Placeholder for future detailed instructions

Features:

- Progress indicator (dots showing current step)
- Back/Next navigation
- Calls `requestCamera()` on camera permission step
- Marks onboarding as complete in chrome.storage on finish

#### `src/hooks/useOnboarding.ts`

Hook to manage onboarding state:

- Checks `chrome.storage.sync` for `onboardingCompleted` flag
- Provides `showOnboarding`, `completeOnboarding()`, `showOnboardingAgain()` functions
- Used by PopupApp to conditionally render onboarding vs main UI

### 7. Content Script (Overlay Injection)

#### `src/content/index.tsx`

```typescript
import { createRoot } from 'react-dom/client';
import { OverlayApp } from '../overlay/OverlayApp';

let overlayRoot: HTMLDivElement | null = null;

chrome.runtime.onMessage.addListener((message: ExtensionMessage) => {
  if (message.type === MessageType.ENABLE_EXTENSION) {
    if (!overlayRoot) {
      overlayRoot = document.createElement('div');
      overlayRoot.id = 'handwave-overlay-root';
      document.body.appendChild(overlayRoot);
      
      const root = createRoot(overlayRoot);
      root.render(<OverlayApp />);
    }
  } else if (message.type === MessageType.DISABLE_EXTENSION) {
    if (overlayRoot) {
      overlayRoot.remove();
      overlayRoot = null;
    }
  }
});

// Check initial state
chrome.storage.sync.get(['enabled'], (result) => {
  if (result.enabled) {
    chrome.runtime.sendMessage({ type: MessageType.ENABLE_EXTENSION });
  }
});
```

### 8. Background Service Worker

#### `src/background/index.ts`

```typescript
chrome.runtime.onInstalled.addListener(() => {
  chrome.storage.sync.set({
    enabled: false,
    debugMode: true,
    cameraId: 'default'
  });
});

chrome.runtime.onMessage.addListener((message: ExtensionMessage, sender, sendResponse) => {
  // Relay messages between popup and content scripts
  if (message.type === MessageType.ENABLE_EXTENSION || 
      message.type === MessageType.DISABLE_EXTENSION) {
    chrome.tabs.query({ active: true, currentWindow: true }, (tabs) => {
      if (tabs[0]?.id) {
        chrome.tabs.sendMessage(tabs[0].id, message);
      }
    });
  }
});
```

### 9. Finger State Detection

#### `src/utils/fingerState.ts`

```typescript
import { Landmark } from '../types/hand.types';

const FINGER_INDICES = {
  thumb: [1, 2, 3, 4],
  index: [5, 6, 7, 8],
  middle: [9, 10, 11, 12],
  ring: [13, 14, 15, 16],
  pinky: [17, 18, 19, 20]
};

export function isFingerExtended(landmarks: Landmark[], fingerName: keyof typeof FINGER_INDICES): boolean {
  const indices = FINGER_INDICES[fingerName];
  const tip = landmarks[indices[3]];
  const pip = landmarks[indices[1]];
  
  // Finger extended if tip Y < PIP Y (higher on screen, accounting for normalization)
  const threshold = 0.05;
  return tip.y < pip.y - threshold;
}

export function detectFingerStates(landmarks: Landmark[]): boolean[] {
  return [
    isFingerExtended(landmarks, 'thumb'),
    isFingerExtended(landmarks, 'index'),
    isFingerExtended(landmarks, 'middle'),
    isFingerExtended(landmarks, 'ring'),
    isFingerExtended(landmarks, 'pinky')
  ];
}
```

### 10. Canvas Debug Rendering Helpers

#### `src/utils/debugRenderer.ts`

```typescript
export function drawHandSkeleton(ctx: CanvasRenderingContext2D, hand: Hand, color: string) {
  const connections = [
    [0, 1], [1, 2], [2, 3], [3, 4], // thumb
    [0, 5], [5, 6], [6, 7], [7, 8], // index
    // ... other finger connections
  ];
  
  ctx.strokeStyle = color;
  ctx.lineWidth = 2;
  
  connections.forEach(([start, end]) => {
    const startPoint = hand.landmarks[start];
    const endPoint = hand.landmarks[end];
    
    ctx.beginPath();
    ctx.moveTo(startPoint.x * ctx.canvas.width, startPoint.y * ctx.canvas.height);
    ctx.lineTo(endPoint.x * ctx.canvas.width, endPoint.y * ctx.canvas.height);
    ctx.stroke();
  });
}

export function drawLandmarkIndices(ctx: CanvasRenderingContext2D, landmarks: Landmark[]) {
  ctx.fillStyle = 'white';
  ctx.font = '10px monospace';
  
  landmarks.forEach((landmark, idx) => {
    const x = landmark.x * ctx.canvas.width;
    const y = landmark.y * ctx.canvas.height;
    
    ctx.beginPath();
    ctx.arc(x, y, 3, 0, 2 * Math.PI);
    ctx.fill();
    
    ctx.fillText(idx.toString(), x + 5, y - 5);
  });
}
```

### 11. Build Configuration

#### `vite.config.ts`

```typescript
import { defineConfig } from 'vite';
import react from '@vitejs/plugin-react';
import { crx } from '@crxjs/vite-plugin';
import manifest from './manifest.json';

export default defineConfig({
  plugins: [
    react(),
    crx({ manifest })
  ],
  build: {
    rollupOptions: {
      input: {
        popup: 'src/popup/index.html',
        // content and background handled by manifest
      }
    }
  }
});
```

### 12. Icons & Assets

Generate icons:

- Create base SVG or 128x128 PNG with hand wave gesture
- Use image editing tool or Python script to generate 16, 48, 128px
- Place in `public/icons/`

### 13. Development & Testing

Run dev server with HMR:

```bash
npm run dev
```

Build for production:

```bash
npm run build
```

Load extension in Chrome:

- Navigate to `chrome://extensions/`
- Enable Developer Mode
- Load unpacked â†’ select `dist/` folder

Test checklist:

- Camera permissions requested on first use
- Overlay appears when extension enabled
- Hands detected with visible skeleton overlay
- FPS shows 25+ consistently
- Dragging and resizing works smoothly
- Popup toggle enables/disables overlay
- Debug mode toggle shows/hides debug panel
- No console errors or memory leaks

## Key Technical Decisions

**React + TypeScript**: Component-based architecture for maintainable UI, type safety for landmark data structures and message passing.

**Vite**: Fast HMR for rapid iteration, optimized bundling, native ESM support.

**TensorFlow.js HandPose**: 21 landmarks, good performance, easy to swap via `handDetection.ts` abstraction.

**Custom Hooks**: Encapsulate complex logic (camera, detection loop, dragging) for reusability and testing.

**Tailwind CSS**: Rapid styling, small bundle size, responsive utilities for overlay.

**Shadow DOM / Iframe Alternative**: Use high z-index with CSS isolation instead of iframe for better React performance.

## Success Criteria (Phase 1 Acceptance)

- âœ“ Camera feed displays in draggable, resizable overlay
- âœ“ Hands detected with <100ms latency
- âœ“ All 21 landmarks per hand tracked accurately
- âœ“ Debug skeleton renders in real-time
- âœ“ FPS counter shows 25+ FPS on modern hardware
- âœ“ Extension toggles on/off from popup
- âœ“ Camera permissions handled gracefully
- âœ“ Works on any webpage without breaking functionality
- âœ“ TypeScript types prevent runtime errors
- âœ“ React components are modular and reusable

## Future Extensibility (Phase 2 Ready)

- Add gesture recognition components that consume finger state
- Build gesture settings UI with React forms
- Integrate gesture visualization in debug panel
- Add custom gesture training interface
- Implement gesture macro builder with drag-and-drop